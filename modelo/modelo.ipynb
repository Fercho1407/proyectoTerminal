{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import timedelta, datetime\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta base de los datasets\n",
    "DATA_DIR = Path(\"../datasets\")  # cámbialo si están en otra carpeta\n",
    "\n",
    "# Cargar ventas y eventos\n",
    "df_ventas = pd.read_csv(DATA_DIR / \"ventas_normalizado.csv\")\n",
    "df_eventos = pd.read_csv(DATA_DIR / \"eventos_productos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0963c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Deja el texto en minúsculas, sin acentos y sin espacios duplicados.\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    texto = str(texto).lower().strip()\n",
    "    texto = unicodedata.normalize(\"NFD\", texto)\n",
    "    texto = \"\".join(c for c in texto if unicodedata.category(c) != \"Mn\")\n",
    "    texto = \" \".join(texto.split())\n",
    "    return texto\n",
    "\n",
    "# Asegurar tipos de fecha\n",
    "df_ventas[\"fecha\"] = pd.to_datetime(df_ventas[\"fecha\"])\n",
    "df_eventos[\"date\"] = pd.to_datetime(df_eventos[\"date\"])\n",
    "\n",
    "# Claves normalizadas de producto\n",
    "df_ventas[\"product_key\"] = df_ventas[\"product_name\"].apply(normalize_text)\n",
    "df_eventos[\"product_key\"] = df_eventos[\"producto_relacionado\"].apply(normalize_text)\n",
    "\n",
    "# Merge left para marcar eventos por (fecha, producto)\n",
    "df_eventos_reduc = df_eventos[[\"event\", \"date\", \"product_key\"]].drop_duplicates()\n",
    "\n",
    "df_ventas_evt = df_ventas.merge(\n",
    "    df_eventos_reduc,\n",
    "    left_on=[\"fecha\", \"product_key\"],\n",
    "    right_on=[\"date\", \"product_key\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# hay_evento = 1 si existe un evento para ese producto en esa fecha\n",
    "df_ventas_evt[\"hay_evento\"] = df_ventas_evt[\"event\"].notna().astype(int)\n",
    "\n",
    "# Ya no necesitamos la columna date del merge\n",
    "df_ventas_evt = df_ventas_evt.drop(columns=[\"date\"])\n",
    "\n",
    "df_ventas_evt.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a115dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = df_ventas_evt.copy()\n",
    "\n",
    "# Calendario\n",
    "ventas[\"anio\"] = ventas[\"fecha\"].dt.year\n",
    "ventas[\"mes\"] = ventas[\"fecha\"].dt.month\n",
    "ventas[\"dia\"] = ventas[\"fecha\"].dt.day\n",
    "ventas[\"dia_semana\"] = ventas[\"fecha\"].dt.weekday\n",
    "ventas[\"es_fin_semana\"] = ventas[\"dia_semana\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# Codificacion ciclica de mes y día de semana\n",
    "ventas[\"mes_sin\"] = np.sin(2 * np.pi * ventas[\"mes\"] / 12)\n",
    "ventas[\"mes_cos\"] = np.cos(2 * np.pi * ventas[\"mes\"] / 12)\n",
    "ventas[\"dow_sin\"] = np.sin(2 * np.pi * ventas[\"dia_semana\"] / 7)\n",
    "ventas[\"dow_cos\"] = np.cos(2 * np.pi * ventas[\"dia_semana\"] / 7)\n",
    "\n",
    "# IDs de producto y categoría\n",
    "ventas[\"product_id\"], product_uniques = pd.factorize(ventas[\"product_name\"])\n",
    "ventas[\"category_id\"], category_uniques = pd.factorize(ventas[\"category_off\"])\n",
    "\n",
    "n_products = len(product_uniques)\n",
    "n_categories = len(category_uniques)\n",
    "print(\"n_products:\", n_products, \"n_categories:\", n_categories)\n",
    "\n",
    "ventas = ventas.sort_values([\"product_id\", \"fecha\"])\n",
    "ventas.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = ventas.sort_values([\"product_id\", \"fecha\"])\n",
    "\n",
    "def crear_ventanas(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crea variables con información de ventas pasadas para cada producto.\n",
    "\n",
    "    La función agrega:\n",
    "    - Ventas de días anteriores (1, 7 y 14 días atrás).\n",
    "    - Promedios de ventas recientes (7, 28 y 90 días),\n",
    "      usando solo datos del pasado para no afectar el entrenamiento.\n",
    "\n",
    "    Estas variables ayudan al modelo a aprender patrones\n",
    "    como tendencias y comportamientos semanales o mensuales.\n",
    "\n",
    "    Parámetros:\n",
    "    df : DataFrame con columnas `product_id` y `ventas`.\n",
    "\n",
    "    Retorna:\n",
    "    El mismo DataFrame con nuevas columnas de apoyo para predicción.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    g = df.groupby(\"product_id\")[\"ventas\"]\n",
    "    df[\"lag_1\"] = g.shift(1)\n",
    "    df[\"lag_7\"] = g.shift(7)\n",
    "    df[\"lag_14\"] = g.shift(14)\n",
    "    df[\"media_7\"] = g.shift(1).rolling(7).mean()\n",
    "    df[\"media_28\"] = g.shift(1).rolling(28).mean()\n",
    "    df[\"media_90\"] = g.shift(1).rolling(90).mean()\n",
    "    return df\n",
    "\n",
    "ventas = crear_ventanas(ventas)\n",
    "\n",
    "# Eliminamos filas sin historial suficiente\n",
    "ventas_modelo = ventas.dropna(subset=[\n",
    "    \"lag_1\", \"lag_7\", \"lag_14\",\n",
    "    \"media_7\", \"media_28\", \"media_90\"\n",
    "]).copy()\n",
    "\n",
    "ventas_modelo.shape, ventas_modelo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0891c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_corte_test = pd.to_datetime(\"2025-06-01\")\n",
    "VAL_DAYS = 60\n",
    "fecha_inicio_val = fecha_corte_test - pd.Timedelta(days=VAL_DAYS)\n",
    "\n",
    "mask_train = ventas_modelo[\"fecha\"] < fecha_inicio_val\n",
    "mask_val   = (ventas_modelo[\"fecha\"] >= fecha_inicio_val) & (ventas_modelo[\"fecha\"] < fecha_corte_test)\n",
    "mask_test  = ventas_modelo[\"fecha\"] >= fecha_corte_test\n",
    "\n",
    "df_train = ventas_modelo.loc[mask_train].copy()\n",
    "df_val   = ventas_modelo.loc[mask_val].copy()\n",
    "df_test  = ventas_modelo.loc[mask_test].copy()\n",
    "\n",
    "print(df_train.shape, df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e629dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"product_id\", \"category_id\", \"perecedero\",\n",
    "    \"precio\", \"en_temporada\", \"hay_evento\",\n",
    "    \"anio\", \"mes\", \"dia_semana\", \"es_fin_semana\",\n",
    "    \"mes_sin\", \"mes_cos\", \"dow_sin\", \"dow_cos\",\n",
    "    \"lag_1\", \"lag_7\", \"lag_14\", \"media_7\", \"media_28\", \"media_90\"\n",
    "]\n",
    "target_col = \"ventas\"\n",
    "\n",
    "# Asegurar numérico básico\n",
    "for c in features:\n",
    "    df_train[c] = pd.to_numeric(df_train[c], errors=\"coerce\")\n",
    "    df_val[c]   = pd.to_numeric(df_val[c], errors=\"coerce\")\n",
    "    df_test[c]  = pd.to_numeric(df_test[c], errors=\"coerce\")\n",
    "\n",
    "df_train[target_col] = pd.to_numeric(df_train[target_col], errors=\"coerce\")\n",
    "df_val[target_col]   = pd.to_numeric(df_val[target_col], errors=\"coerce\")\n",
    "df_test[target_col]  = pd.to_numeric(df_test[target_col], errors=\"coerce\")\n",
    "\n",
    "# Quitar filas con NaN en lo necesario\n",
    "df_train = df_train.dropna(subset=features + [target_col])\n",
    "df_val   = df_val.dropna(subset=features + [target_col])\n",
    "df_test  = df_test.dropna(subset=features + [target_col])\n",
    "\n",
    "X_train = df_train[features].astype(\"float32\").to_numpy()\n",
    "X_val   = df_val[features].astype(\"float32\").to_numpy()\n",
    "X_test  = df_test[features].astype(\"float32\").to_numpy()\n",
    "\n",
    "y_train = df_train[target_col].astype(\"float32\").to_numpy()\n",
    "y_val   = df_val[target_col].astype(\"float32\").to_numpy()\n",
    "y_test  = df_test[target_col].astype(\"float32\").to_numpy()\n",
    "\n",
    "# Escalar TODO menos IDs (product_id y category_id)\n",
    "id_idx = [features.index(\"product_id\"), features.index(\"category_id\")]\n",
    "num_idx = [i for i in range(len(features)) if i not in id_idx]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[:, num_idx] = scaler.fit_transform(X_train[:, num_idx])\n",
    "X_val[:, num_idx]   = scaler.transform(X_val[:, num_idx])\n",
    "X_test[:, num_idx]  = scaler.transform(X_test[:, num_idx])\n",
    "\n",
    "# Target en log\n",
    "y_train_t = np.log1p(y_train)\n",
    "y_val_t   = np.log1p(y_val)\n",
    "y_test_t  = np.log1p(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=keras.losses.Huber(delta=0.5),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c511217",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_t,\n",
    "    validation_data=(X_val, y_val_t),\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7030a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "pred_log = model.predict(X_test, verbose=0).reshape(-1)\n",
    "pred = np.expm1(pred_log)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "\n",
    "print(f\"TEST MAE : {mae:.4f}\")\n",
    "print(f\"TEST RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9335f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción\n",
    "y_pred_log = model.predict(X_test, verbose=0).ravel()\n",
    "\n",
    "# Volver a escala real\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "# Evitar predicciones negativas\n",
    "y_pred = np.clip(y_pred, 0, None)\n",
    "\n",
    "# Métricas contra ventas reales\n",
    "mae_nn = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# MAPE seguro (evitar división entre 0)\n",
    "y_test_safe = np.clip(y_test, 1e-6, None)\n",
    "mape_nn = mean_absolute_percentage_error(y_test_safe, y_pred)\n",
    "\n",
    "print(\"Neural Network MAE:\", mae_nn)\n",
    "print(\"Neural Network MAPE:\", mape_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val loss\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Pérdida (loss)\")\n",
    "plt.title(\"Curva de entrenamiento - Red Neuronal (Big Error Loss)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc972cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha=0.3, s=10)\n",
    "\n",
    "max_val = max(y_test.max(), y_pred.max())\n",
    "plt.plot([0, max_val], [0, max_val], color=\"red\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Ventas reales\")\n",
    "plt.ylabel(\"Ventas predichas\")\n",
    "plt.title(\"Real vs Predicho - Red Neuronal\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_producto = \"pasta espagueti 500 g\"\n",
    "\n",
    "# 1) Filtrar el test SOLO para ese producto (usando df_test)\n",
    "df_test_prod = df_test[df_test[\"product_name\"] == nombre_producto].copy()\n",
    "\n",
    "if df_test_prod.empty:\n",
    "    print(\"No hay datos en TEST para:\", nombre_producto)\n",
    "else:\n",
    "    # 2) Preparar X del producto usando las MISMAS features y el MISMO escalado\n",
    "    X_prod = df_test_prod[features].astype(\"float32\").to_numpy()\n",
    "\n",
    "    # Escalar solo numéricas (igual que hiciste antes)\n",
    "    X_prod[:, num_idx] = scaler.transform(X_prod[:, num_idx])\n",
    "\n",
    "    # 3) Predicción (en log) y volver a escala real\n",
    "    y_pred_log = model.predict(X_prod, verbose=0).ravel()\n",
    "    y_pred_prod = np.expm1(y_pred_log)\n",
    "    y_pred_prod = np.clip(y_pred_prod, 0, None)\n",
    "\n",
    "    # 4) Valores reales y fechas\n",
    "    fechas_prod = df_test_prod[\"fecha\"]\n",
    "    y_real_prod = df_test_prod[target_col].astype(\"float32\").to_numpy()\n",
    "\n",
    "    # 5) Graficar\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(fechas_prod, y_real_prod, label=\"Real\", linewidth=2)\n",
    "    plt.plot(fechas_prod, y_pred_prod, label=\"Predicho NN\", linewidth=2)\n",
    "    plt.xlabel(\"Fecha\")\n",
    "    plt.ylabel(\"Ventas\")\n",
    "    plt.title(f\"Ventas reales vs predichas - {nombre_producto}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "\n",
    "def predict_on_feature_df(\n",
    "    df_feat: pd.DataFrame,\n",
    "    product_name: str,\n",
    "    model,\n",
    "    scaler,\n",
    "    features: List[str],\n",
    "    num_idx: np.ndarray,\n",
    "    target_col: str = \"ventas\",\n",
    "    date_col: str = \"fecha\",\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Predice sobre df_feat (ya contiene las columnas de features).\n",
    "    Devuelve series lista para graficar: date, real, pred.\n",
    "\n",
    "    Nota: asume que el modelo fue entrenado en log1p(y) y se revierte con expm1.\n",
    "    \"\"\"\n",
    "    df_prod = df_feat[df_feat[\"product_name\"] == product_name].copy()\n",
    "    if df_prod.empty:\n",
    "        return {\"product_name\": product_name, \"count\": 0, \"series\": []}\n",
    "\n",
    "    # X\n",
    "    X = df_prod[features].astype(\"float32\").to_numpy()\n",
    "\n",
    "    # Escalar SOLO numéricas (igual que en notebook)\n",
    "    X[:, num_idx] = scaler.transform(X[:, num_idx])\n",
    "\n",
    "    # Predicción (log) -> escala real\n",
    "    y_pred_log = model.predict(X, verbose=0).ravel()\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "\n",
    "    # Real y fechas\n",
    "    fechas = pd.to_datetime(df_prod[date_col], errors=\"coerce\")\n",
    "    y_real = df_prod[target_col].astype(\"float32\").to_numpy()\n",
    "\n",
    "    series = []\n",
    "    for i in range(len(df_prod)):\n",
    "        d = fechas.iloc[i]\n",
    "        if pd.isna(d):\n",
    "            continue\n",
    "        series.append({\n",
    "            \"date\": d.date().isoformat(),\n",
    "            \"real\": float(y_real[i]),\n",
    "            \"pred\": float(np.round(y_pred[i], 2)),\n",
    "        })\n",
    "\n",
    "    return {\"product_name\": product_name, \"count\": len(series), \"series\": series}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asegurar que df_eventos tenga clave normalizada\n",
    "df_eventos[\"product_key\"] = df_eventos[\"producto_relacionado\"].apply(normalize_text)\n",
    "df_eventos[\"date\"] = pd.to_datetime(df_eventos[\"date\"])\n",
    "\n",
    "def hay_evento_en_fecha(nombre_producto: str, fecha: pd.Timestamp) -> int:\n",
    "    \"\"\"\n",
    "    Regresa 1 si ese producto tiene un evento exactamente en esa fecha, 0 en caso contrario.\n",
    "    \"\"\"\n",
    "    pkey = normalize_text(nombre_producto)\n",
    "    eventos_prod = df_eventos[df_eventos[\"product_key\"] == pkey]\n",
    "    if eventos_prod.empty:\n",
    "        return 0\n",
    "    return int(fecha.normalize() in eventos_prod[\"date\"].dt.normalize().values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predecir_proximos_dias(nombre_producto: str, dias: int = 7) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predice las ventas de los próximos 'dias' días para un producto específico\n",
    "    usando el modelo de red neuronal entrenado.\n",
    "    \n",
    "    Usa:\n",
    "      - ventas_modelo (histórico con lags ya calculados)\n",
    "      - model (red neuronal)\n",
    "      - scaler (StandardScaler)\n",
    "      - features (lista de columnas de entrada)\n",
    "      - df_eventos (para hay_evento)\n",
    "    \"\"\"\n",
    "    # 1. Obtener el product_id y el histórico de ese producto\n",
    "    df_prod_hist = ventas_modelo[ventas_modelo[\"product_name\"] == nombre_producto].copy()\n",
    "    if df_prod_hist.empty:\n",
    "        raise ValueError(f\"No se encontró histórico para el producto: {nombre_producto}\")\n",
    "    \n",
    "    df_prod_hist = df_prod_hist.sort_values(\"fecha\")\n",
    "    \n",
    "    # Información estática del producto (tomamos la última fila)\n",
    "    last_row = df_prod_hist.iloc[-1]\n",
    "    product_id = int(last_row[\"product_id\"])\n",
    "    category_id = int(last_row[\"category_id\"])\n",
    "    perecedero = int(last_row[\"perecedero\"])\n",
    "    precio_ultimo = float(last_row[\"precio\"])\n",
    "    \n",
    "    # Para lags y medias necesitamos la serie histórica de ventas\n",
    "    hist_fechas = list(df_prod_hist[\"fecha\"])\n",
    "    hist_ventas = list(df_prod_hist[\"ventas\"].astype(float))\n",
    "    \n",
    "    # 2. Fecha inicial para predicciones: día siguiente del último dato\n",
    "    fecha_actual = df_prod_hist[\"fecha\"].max()\n",
    "    \n",
    "\n",
    "    # Lista donde vamos acumulando resultados\n",
    "    pred_rows = []\n",
    "    \n",
    "    for i in range(dias):\n",
    "        fecha_pred = fecha_actual + timedelta(days=1)\n",
    "        \n",
    "        # --- Calendario ---\n",
    "        anio = fecha_pred.year\n",
    "        mes = fecha_pred.month\n",
    "        dia_semana = fecha_pred.weekday()   # 0 lunes, 6 domingo\n",
    "        es_fin_semana = 1 if dia_semana in [5, 6] else 0\n",
    "        \n",
    "        mes_sin = np.sin(2 * np.pi * mes / 12)\n",
    "        mes_cos = np.cos(2 * np.pi * mes / 12)\n",
    "        dow_sin = np.sin(2 * np.pi * dia_semana / 7)\n",
    "        dow_cos = np.cos(2 * np.pi * dia_semana / 7)\n",
    "        \n",
    "        # --- Eventos y flags ---\n",
    "        hay_evento = hay_evento_en_fecha(nombre_producto, fecha_pred)\n",
    "        \n",
    "        # Para simplificar: asumimos mismo patrón de promo y temporada que el último día\n",
    "        en_temporada = int(last_row[\"en_temporada\"])\n",
    "        \n",
    "        # --- Lags y medias basados en hist_ventas (que vamos actualizando) ---\n",
    "        # Si el histórico es corto, usamos lo que haya\n",
    "        lag_1 = hist_ventas[-1]\n",
    "        lag_7 = hist_ventas[-7] if len(hist_ventas) >= 7 else hist_ventas[0]\n",
    "        lag_14 = hist_ventas[-14] if len(hist_ventas) >= 14 else hist_ventas[0]\n",
    "        \n",
    "        media_7 = float(np.mean(hist_ventas[-7:])) if len(hist_ventas) >= 2 else hist_ventas[-1]\n",
    "        media_28 = float(np.mean(hist_ventas[-28:])) if len(hist_ventas) >= 2 else hist_ventas[-1]\n",
    "        media_90 = float(np.mean(hist_ventas[-90:])) if len(hist_ventas) >= 2 else hist_ventas[-1]\n",
    "        \n",
    "        # --- Armar vector de features en el mismo orden que 'features' ---\n",
    "        feature_dict = {\n",
    "            \"product_id\": product_id,\n",
    "            \"category_id\": category_id,\n",
    "            \"perecedero\": perecedero,\n",
    "            \"precio\": precio_ultimo,          # podrías dinamizar esto futuramente\n",
    "            \"en_temporada\": en_temporada,\n",
    "            \"hay_evento\": hay_evento,\n",
    "            \"anio\": anio,\n",
    "            \"mes\": mes,\n",
    "            \"dia_semana\": dia_semana,\n",
    "            \"es_fin_semana\": es_fin_semana,\n",
    "            \"mes_sin\": mes_sin,\n",
    "            \"mes_cos\": mes_cos,\n",
    "            \"dow_sin\": dow_sin,\n",
    "            \"dow_cos\": dow_cos,\n",
    "            \"lag_1\": lag_1,\n",
    "            \"lag_7\": lag_7,\n",
    "            \"lag_14\": lag_14,\n",
    "            \"media_7\": media_7,\n",
    "            \"media_28\": media_28,\n",
    "            \"media_90\": media_90,\n",
    "        }\n",
    "        \n",
    "        # Convertir a DataFrame para pasar por el scaler\n",
    "        X_fut = pd.DataFrame([feature_dict])[features].astype(\"float32\").to_numpy()\n",
    "\n",
    "        # Escalar SOLO columnas numéricas, igual que en entrenamiento\n",
    "        X_fut[:, num_idx] = scaler.transform(X_fut[:, num_idx])\n",
    "\n",
    "        # Ya queda listo para el modelo\n",
    "        X_fut_scaled = X_fut\n",
    "        \n",
    "        # Predicción con el modelo\n",
    "        y_pred = float(model.predict(X_fut_scaled, verbose=0).ravel()[0])\n",
    "        \n",
    "        # Guardar resultado\n",
    "        pred_rows.append({\n",
    "            \"fecha\": fecha_pred,\n",
    "            \"product_name\": nombre_producto,\n",
    "            \"prediccion_ventas\": max(y_pred, 0.0),  # evitar negativos\n",
    "            \"hay_evento\": hay_evento,\n",
    "            \"en_temporada\": en_temporada\n",
    "        })\n",
    "        \n",
    "        # Actualizar histórico para el siguiente día (usamos la predicción como nueva venta)\n",
    "        hist_fechas.append(fecha_pred)\n",
    "        hist_ventas.append(max(y_pred, 0.0))\n",
    "        \n",
    "        # Avanzar fecha\n",
    "        fecha_actual = fecha_pred\n",
    "    \n",
    "    df_pred = pd.DataFrame(pred_rows)\n",
    "    return df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66caab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_producto = \"aguacate\"\n",
    "\n",
    "df_pred_semana = predecir_proximos_dias(nombre_producto, dias=7)\n",
    "print(df_pred_semana)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_pred_semana[\"fecha\"], df_pred_semana[\"prediccion_ventas\"], marker=\"o\")\n",
    "plt.title(f\"Predicción próximas ventas - {nombre_producto}\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Unidades predichas\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0088d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_producto = \"tejocote\"  # cámbialo a uno que exista en tu dataset\n",
    "\n",
    "df_pred_semana = predecir_proximos_dias(nombre_producto, dias=12)\n",
    "print(df_pred_semana)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_pred_semana[\"fecha\"], df_pred_semana[\"prediccion_ventas\"], marker=\"o\")\n",
    "plt.title(f\"Predicción próximas ventas - {nombre_producto}\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Unidades predichas\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sugerir_stock(nombre_producto: str,\n",
    "                  dias: int = 7,\n",
    "                  factor_seguridad: float = 1.2):\n",
    "    \"\"\"\n",
    "    Calcula la cantidad de stock sugerido para un producto en un horizonte de 'dias',\n",
    "    usando el modelo de predicción + un factor de seguridad.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    nombre_producto : str\n",
    "        Nombre EXACTO del producto tal como aparece en ventas_modelo[\"product_name\"].\n",
    "    dias : int, opcional (default=7)\n",
    "        Número de días a futuro que se quieren cubrir con el stock.\n",
    "    factor_seguridad : float, opcional (default=1.2)\n",
    "        Factor multiplicador para protegerte ante errores del modelo y variaciones\n",
    "        inesperadas en la demanda.\n",
    "        Ejemplo: 1.2 = 20% extra de colchón.\n",
    "\n",
    "    Regresa:\n",
    "    --------\n",
    "    df_pred : pandas.DataFrame\n",
    "        Tabla con la predicción diaria:\n",
    "        [fecha, product_name, prediccion_ventas, hay_evento, en_promocion, en_temporada]\n",
    "    demanda_esperada : float\n",
    "        Suma de las unidades esperadas a vender en esos 'dias'.\n",
    "    stock_sugerido : float\n",
    "        Unidades recomendadas de stock (demanda_esperada * factor_seguridad).\n",
    "        Se redondea hacia arriba.\n",
    "    \"\"\"\n",
    "    # 1. Obtener predicciones diarias\n",
    "    df_pred = predecir_proximos_dias(nombre_producto, dias=dias)\n",
    "\n",
    "    # 2. Demanda esperada total (suma de las predicciones diarias)\n",
    "    demanda_esperada = df_pred[\"prediccion_ventas\"].sum()\n",
    "\n",
    "    # 3. Aplicar factor de seguridad\n",
    "    stock_sugerido = np.ceil(demanda_esperada * factor_seguridad)\n",
    "\n",
    "    return df_pred, demanda_esperada, stock_sugerido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "producto = \"tejocote\"   # cambia por uno que exista en tu dataset\n",
    "dias_horizonte = 31\n",
    "factor_seg = 1.0   # 20% de colchón\n",
    "\n",
    "df_pred, demanda_esperada, stock_sugerido = sugerir_stock(\n",
    "    nombre_producto=producto,\n",
    "    dias=dias_horizonte,\n",
    "    factor_seguridad=factor_seg\n",
    ")\n",
    "\n",
    "print(f\"Producto: {producto}\")\n",
    "print(f\"Horizonte: {dias_horizonte} días\")\n",
    "print(f\"Demanda esperada en {dias_horizonte} días: {demanda_esperada:.2f} unidades\")\n",
    "print(f\"Factor de seguridad: {factor_seg}\")\n",
    "print(f\"Stock sugerido: {stock_sugerido:.0f} unidades\")\n",
    "\n",
    "print(\"\\nDetalle por día:\")\n",
    "display(df_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d0b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dependenciasPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
